{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install torch tokenizers numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "mps_device = None\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../.data/\"\n",
    "TEST_DATA_FILE = DATA_PATH + \"test_data.txt\"\n",
    "VALIDATION_DATA_FILE = DATA_PATH + \"validation_data.txt\"\n",
    "TOKENIZER_PATH = \"../src/tokenizer/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_DATA_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "    train_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VALIDATION_DATA_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "    validation_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\n",
    "    f\"{TOKENIZER_PATH}/kn1ght-tokenizer.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = tokenizer.encode(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training character length: 153214691\n",
      "training tokens length: 42895705\n"
     ]
    }
   ],
   "source": [
    "print(\"training character length:\", len(train_text))\n",
    "print(\"training tokens length:\", train_tokens.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tokens = tokenizer.encode(validation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation character length: 153145037\n",
      "validation tokens length: 42875072\n"
     ]
    }
   ],
   "source": [
    "print(\"validation character length:\", len(validation_text))\n",
    "print(\"validation tokens length:\", validation_tokens.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.tensor(train_tokens.ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = torch.tensor(validation_tokens.ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.d4 Nf6 2.Nf3 e6 3.Bg5\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "print(tokenizer.decode(list(train_data[: block_size + 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([0]) () the target is: 48 (1.)\n",
      "when input is tensor([ 0, 48]) (1.) the target is: 77 (d4)\n",
      "when input is tensor([ 0, 48, 77]) (1.d4) the target is: 104 ( Nf6)\n",
      "when input is tensor([  0,  48,  77, 104]) (1.d4 Nf6) the target is: 107 ( 2.)\n",
      "when input is tensor([  0,  48,  77, 104, 107]) (1.d4 Nf6 2.) the target is: 105 (Nf3)\n",
      "when input is tensor([  0,  48,  77, 104, 107, 105]) (1.d4 Nf6 2.Nf3) the target is: 177 ( e6)\n",
      "when input is tensor([  0,  48,  77, 104, 107, 105, 177]) (1.d4 Nf6 2.Nf3 e6) the target is: 108 ( 3.)\n",
      "when input is tensor([  0,  48,  77, 104, 107, 105, 177, 108]) (1.d4 Nf6 2.Nf3 e6 3.) the target is: 228 (Bg5)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1 : block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(\n",
    "        f\"when input is {context} ({tokenizer.decode(list(context))}) the target is: {target} ({tokenizer.decode([target])})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[1006,    5,  180,  823,  356,    5,  185, 1205],\n",
      "        [   5,  180,  626,  471,    5,  185,  388,  384],\n",
      "        [1239,  134,  785,  494,  138,  637,  221,  141],\n",
      "        [ 246,  104,  110,  137,  182,  111,   80,  162]], device='mps:0')\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[   5,  180,  823,  356,    5,  185, 1205,  608],\n",
      "        [ 180,  626,  471,    5,  185,  388,  384,    5],\n",
      "        [ 134,  785,  494,  138,  637,  221,  141,  416],\n",
      "        [ 104,  110,  137,  182,  111,   80,  162,  112]], device='mps:0')\n",
      "----\n",
      "when input is [1006] the target: 5\n",
      "when input is [1006, 5] the target: 180\n",
      "when input is [1006, 5, 180] the target: 823\n",
      "when input is [1006, 5, 180, 823] the target: 356\n",
      "when input is [1006, 5, 180, 823, 356] the target: 5\n",
      "when input is [1006, 5, 180, 823, 356, 5] the target: 185\n",
      "when input is [1006, 5, 180, 823, 356, 5, 185] the target: 1205\n",
      "when input is [1006, 5, 180, 823, 356, 5, 185, 1205] the target: 608\n",
      "when input is [5] the target: 180\n",
      "when input is [5, 180] the target: 626\n",
      "when input is [5, 180, 626] the target: 471\n",
      "when input is [5, 180, 626, 471] the target: 5\n",
      "when input is [5, 180, 626, 471, 5] the target: 185\n",
      "when input is [5, 180, 626, 471, 5, 185] the target: 388\n",
      "when input is [5, 180, 626, 471, 5, 185, 388] the target: 384\n",
      "when input is [5, 180, 626, 471, 5, 185, 388, 384] the target: 5\n",
      "when input is [1239] the target: 134\n",
      "when input is [1239, 134] the target: 785\n",
      "when input is [1239, 134, 785] the target: 494\n",
      "when input is [1239, 134, 785, 494] the target: 138\n",
      "when input is [1239, 134, 785, 494, 138] the target: 637\n",
      "when input is [1239, 134, 785, 494, 138, 637] the target: 221\n",
      "when input is [1239, 134, 785, 494, 138, 637, 221] the target: 141\n",
      "when input is [1239, 134, 785, 494, 138, 637, 221, 141] the target: 416\n",
      "when input is [246] the target: 104\n",
      "when input is [246, 104] the target: 110\n",
      "when input is [246, 104, 110] the target: 137\n",
      "when input is [246, 104, 110, 137] the target: 182\n",
      "when input is [246, 104, 110, 137, 182] the target: 111\n",
      "when input is [246, 104, 110, 137, 182, 111] the target: 80\n",
      "when input is [246, 104, 110, 137, 182, 111, 80] the target: 162\n",
      "when input is [246, 104, 110, 137, 182, 111, 80, 162] the target: 112\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1997)  # https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov\n",
    "batch_size = 4  # how many independent sequences will we process in parallel?\n",
    "block_size = 8  # what is the maximum context length for predictions?\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)).to(\"mps\")\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix]).to(\"mps\")\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix]).to(\"mps\")\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "for b in range(batch_size):  # batch dimension\n",
    "    for t in range(block_size):  # time dimension\n",
    "        context = xb[b, : t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4096])\n",
      "tensor(9.3236, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      " h2 Kg6 Nxe2Bxd5 a6 Rff7Ne5 Nc5 Kxa2 Bxa6 Raxa3N2d3 Ndc3 Naxb4 Nhxg3Rg5 Nge5xe1Ndb2Bxe5Ndxf61Ke7R3e2 Rge3 Nxg1 Rgg5 Nc4 Qf4 R8f7N7d5Ncxd7Rexd3Rhd5 R2b3Nxe6 Nhg5 Nxg7R dxc4Rdxc6 Kg1 Bxa4 R1a2 Rce3 Kc3 R8g7Rxc4 Kxb2Nh8 R2c6 N4f6bxc8bxa3 R8xb5R5d2Rxh8 N R8xf7 Rhxh2 Ndb5Rd8R6e4 Nbxa4 19.R7c5 R8f4Nexf6Rhe5 R6d7 R1c4Kxh3Rfd2Rdxf1Rexd6 Nexc4Red7 Rbb8 Bd6 Rdd8 R6e7Nbc6 R3g6Rdxe3 Rgg8 Rge5 N5 Naxc4R6f2dxc3 Nxa6 Nf7Rbxb2Nce3Nbxd6 Nbc8 Kg2N6f5 Rexe6Ng7\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1997)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size, device=\"mps\")\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx)  # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(tokenizer.get_vocab_size())\n",
    "\n",
    "if mps_device is not None:\n",
    "    m.to(mps_device)\n",
    "\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(\n",
    "    tokenizer.decode(\n",
    "        m.generate(\n",
    "            idx=torch.zeros((1, 1), dtype=torch.long, device=\"mps\"), max_new_tokens=100\n",
    "        )[0].tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.949321746826172\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):  # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rf Ndf8R1\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tokenizer.decode(\n",
    "        m.generate(\n",
    "            idx=torch.zeros((1, 1), dtype=torch.long, device=\"mps\"), max_new_tokens=3\n",
    "        )[0].tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
